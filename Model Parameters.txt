# hyperparameters
batch_size = 64 # how many independent sequences will we process in parallel?
block_size = 512 # what is the maximum context length for predictions?
max_iters = 10000
eval_interval = 100
learning_rate = 0.0001
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
eval_iters = 200
n_embd = 512 # embedding dimension
n_head = 8 # number of heads (512/8 = 64 dimensions per head)
n_layer = 6
dropout = 0.2